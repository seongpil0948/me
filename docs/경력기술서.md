# 경력 기술서

**최성필 (Seongpil Choi)**

---

## 목차

1. [경력 개요](#경력-개요)
2. [아이디에스앤트러스트 (idstrust)](#1-아이디에스앤트러스트-idstrust)
3. [애버커스 (Abacus)](#2-애버커스-abacus)
4. [인아웃박스 (Inoutbox)](#3-인아웃박스-inoutbox)
5. [인텔리시스 (Intellisys)](#4-인텔리시스-intellisys)
6. [기술 철학 및 업무 방식](#기술-철학-및-업무-방식)

---

## 경력 개요

**총 경력**: 6년 (2020.02 ~ 현재)

| 기간              | 회사                 | 직급/역할                  | 주요 기술                                  |
| ----------------- | -------------------- | -------------------------- | ------------------------------------------ |
| 2024.06 ~ 현재    | 아이디에스앤트러스트 | 선임연구원                 | OpenTelemetry, Kafka, Airflow, EKS, APISIX |
| 2023.05 ~ 2024.06 | 애버커스             | 선임연구원 (Frontend Lead) | Kubernetes, Keycloak, RabbitMQ, Three.js   |
| 2022.06 ~ 2023.03 | 인아웃박스           | 1인 풀스택 (창업)          | Flutter, Django, GCP, Firebase             |
| 2020.02 ~ 2022.06 | 인텔리시스           | 서비스 연구원              | Argo Workflows, RabbitMQ, Vue.js, ML       |

---

## 1. 아이디에스앤트러스트 (idstrust)

### 기본 정보

- **기간**: 2024년 06월 ~ 현재 (재직중)
- **직급**: 선임연구원
- **소속**: TheShop 이커머스 플랫폼 지원팀
- **회사 소개**: 대웅 그룹 IT 계열사
- **담당 업무**: TheShop 플랫폼 인프라 최적화, 분산 시스템 관리, 신규 서비스 아키텍처 설계 주도

### 담당 시스템 규모

**비즈니스 규모**

- 연 5천억원 거래 규모
- 도매, 병원/약국/동물병원/한의원 전문몰 운영

**사용자 및 트래픽**

- 일 1만 ~ 10만 사용자
- 일 200GB (주말) ~ 500GB (평일)
- 피크 시: 20.8 GB/시간, 347 MB/분
- Site-to-Site VPN: 1.25Gbps

**데이터 규모**

- 데이터 레이크: 월 20TB 비정형 데이터 처리 (주 5TB)
- 관측 데이터: 수십 개 Application의 월 3TB Trace 데이터
- Kafka: 일 10억 건 메시지
- Airflow: 200개 이상 배치 작업

### 주요 프로젝트

#### 1.1. 모니터링 시스템 고도화 (Legacy End-to-End 관측 환경 구축)

**Challenge**

- Scouter 기반 레거시 모니터링의 한계
- 컨테이너 서비스 메시 환경에서의 관측 단절
- 10년 이상 운영된 레거시 모놀리식 시스템과 신규 MSA 혼재
- 신규 어드민 시스템 장애 발생 시 평균 **18시간** 소요되는 원인 파악 시간
- 개발팀의 생산성 심각한 저하

**Solution**

_기술적 접근_

- **OpenTelemetry** 기반 통합 관측(Observability) 시스템으로 마이그레이션 주도
- 12대 서버에 OpenTelemetry Collector 구축
- Grafana 대시보드 연동으로 실시간 시각화
- End-to-End 분산 추적(Distributed Tracing), 메트릭, 로그를 단일 플랫폼에서 수집
- **커스텀 Exporter 개발**: Go-lang으로 AWS 및 EKS 환경에 최적화된 Exporter 구현
- OpenTelemetry 오픈소스 프로젝트에 기여

_조직적 접근_

- 개발팀 대상 OpenTelemetry 활용 교육 세션 진행
- 우선순위 기반 알림 시스템 구축 (Slack, Jira 연동)
- 장애 발생 시 즉각적인 알림 및 트레이싱 제공

**Achievement**

- **평균 장애 인지 시간(MTTI) 99.5% 단축**: 18시간 → **10분 이내**
- 개발팀 생산성 극대화: 장애 대응 시간 절감으로 비즈니스 로직 개발 집중
- OpenTelemetry 오픈소스 커뮤니티 기여
- 100개 이상 컨테이너의 완벽한 관측 가능성 확보

**사용 기술**

- OpenTelemetry (Go-lang Custom Exporter)
- Grafana, Prometheus, Tempo, Loki
- CloudWatch
- Slack API, Jira API

**배운 점**

- 기술 도입은 기술 그 자체가 아닌, **팀의 Pain Point 해결**이 목적이어야 함
- Data-driven 접근: MTTI 18시간이 실질적으로 엔지니어 공수 얼마에 해당하는지 데이터로 증명
- 측정이 시작되어야 개선 가능: 관측성은 DevOps의 시작점

---

#### 1.2. 인프라 비용 최적화 프로젝트

**Challenge**

- 무작위로 저장된 Amazon S3 데이터
- 월 **$5,000**의 비효율적 운영 비용 발생
- 사용 패턴 분석 부재로 최적화 불가

**Solution**

_데이터 분석_

- CloudWatch와 EMF(Embedded Metric Format)를 활용한 실시간 사용 패턴 분석
- 버킷별, 경로별 접근 빈도 및 데이터 생명주기 조사
- 비즈니스 요구사항과 데이터 보존 정책 매핑

_자동화 구현_

- 버킷 경로별 S3 생명주기(Lifecycle) 정책 수립
- 자동 아카이빙(Glacier) 및 삭제 프로세스 구현
- 분석 데이터를 기반으로 EC2 인스턴스 Right-sizing 수행

**Achievement**

- **월 운영 비용 50% 절감**: $5,000 → **$2,500**
- 연간 **$30,000** 절감 효과
- 자동화된 비용 최적화 프로세스 구축
- CloudWatch 대시보드로 비용 트렌드 실시간 모니터링

**사용 기술**

- AWS S3 Lifecycle Policies
- CloudWatch, EMF (Embedded Metric Format)
- Lambda (자동화 스크립트)
- EC2 Right-sizing

---

#### 1.3. API 게이트웨이 이관 (Nginx → APISIX)

**Challenge**

- 다중 서버에 분산된 Nginx 기반 라우팅 설정
- 관리 복잡성 증가 및 일관성 부재
- 마이크로서비스 도입에 따른 중앙화된 트래픽 제어/모니터링 체계 부재
- Rate limiting, Circuit breaker 패턴 적용 어려움

**Solution**

_마이그레이션 전략_

- 기존 Nginx 라우팅 룰 분석 및 문서화
- **APISIX API Gateway**로 단계적 이관
- Canary 배포를 통한 점진적 트래픽 전환
- Rollback 계획 수립 및 모니터링 강화

_중앙화 구현_

- APISIX를 통한 트래픽 중앙화 및 인증/인가 통합 관리
- Rate limiting 및 Circuit breaker 패턴 적용
- Lua 스크립팅을 활용한 커스텀 플러그인 개발
- Prometheus + Grafana 실시간 트래픽 분석 대시보드 구축

**Achievement**

- 마이크로서비스 간 통신 안정성 향상
- API 응답 시간 실시간 모니터링 및 병목 지점 즉시 파악
- 중앙화된 인증/인가 체계로 보안 강화
- Lua 스크립팅으로 유연한 라우팅 정책 구현

**사용 기술**

- APISIX API Gateway
- Prometheus, Grafana
- Lua scripting
- Nginx (legacy)

---

#### 1.4. 분산 데이터 처리 인프라 구축 및 운영

**Challenge**

- 대규모 메시지 처리: **일 10억 건**
- **200개 이상**의 배치 작업 관리 필요
- 고가용성(HA) 요구사항
- 메시지 손실 방지 및 재처리 메커니즘 필요

**Solution**

_Apache Kafka 클러스터_

- **3-node 고가용성(HA) 클러스터** 구축
- Replication Factor 3 설정으로 데이터 안정성 확보
- Producer/Consumer 최적화 (batch size, linger.ms 튜닝)
- Partition 전략 수립으로 병렬 처리 극대화

_Redis Sentinel HA_

- Master-Slave 구조의 고가용성 캐싱 시스템 구현
- 자동 Failover 설정으로 서비스 연속성 보장
- Read replica를 통한 읽기 성능 향상

_Apache Airflow 오케스트레이션_

- **5대 서버 클러스터** 구성
- 200개 이상 DAG(Directed Acyclic Graph) 관리
- 작업 의존성 관리 및 재시도 로직 구현
- Slack 알림 연동으로 배치 실패 즉시 감지

**Achievement**

- **일일 10억 건** 메시지 안정적 처리
- **200개 이상** 배치 작업 동시 처리 및 자동화
- Redis Sentinel 도입으로 Failover 시간 50% 단축
- 메시지 손실률 0.001% 이하 유지

**사용 기술**

- Apache Kafka 3-node cluster
- Redis Sentinel (Master-Slave HA)
- Apache Airflow 5-server cluster
- Python (Airflow DAG, Kafka Producer/Consumer)

---

#### 1.5. ECS-API Gateway 기반 고객관리 플랫폼 설계

**Challenge**

- 한정된 온프레미스 서버 리소스
- 클라우드 전환 필요성
- 수동 배포로 인한 긴 배포 시간 (평균 **2시간**)
- 인프라 프로비저닝 수동 작업으로 인한 오류 발생

**Solution**

_서버리스 아키텍처_

- **AWS ECS Fargate**를 활용한 서버리스 컨테이너 아키텍처 구현
- Auto Scaling 설정으로 트래픽에 따른 자동 확장/축소
- Task Definition 최적화로 리소스 효율 극대화

_API 설계 및 보안_

- **API Gateway**를 통한 RESTful API 설계
- 인증/인가 체계 구축 (JWT 기반)
- Rate limiting, Throttling 설정

_IaC 구현_

- **CloudFormation**을 활용한 Infrastructure as Code(IaC) 구현
- 버전 관리를 통한 인프라 변경 이력 추적
- CI/CD 파이프라인에 IaC 통합

_데이터 마이그레이션_

- **Apache Airflow**를 활용한 온프레미스 데이터 이관 파이프라인 구축
- 점진적 마이그레이션 전략으로 서비스 무중단 보장

**Achievement**

- **배포 시간 90% 단축**: 2시간 → **12분**
- 인프라 프로비저닝 완전 자동화
- 운영 효율성 극대화 및 인적 오류 제거
- CloudFormation으로 인프라 버전 관리 체계 확립

**사용 기술**

- AWS ECS Fargate
- AWS API Gateway
- CloudFormation (IaC)
- Apache Airflow (데이터 마이그레이션)
- Docker

---

#### 1.6. 데이터 레이크 기반 비즈니스 지표 시각화

**Challenge**

- 기존 **7일** 제한의 로그 조회 기간
- 장기 데이터 분석 및 장애 대응 한계
- 비즈니스 의사결정을 위한 데이터 부족
- 기획팀/마케팅팀의 데이터 접근성 부재

**Solution**

_데이터 레이크 아키텍처_

- **AWS Glue (Spark 기반)** 와 **Athena (Hive 기반)** 를 활용한 데이터 레이크 구축
- **S3**를 중앙 저장소로 사용하여 로그 장기 보관 (**10년**)
- OpenTelemetry 데이터 (Tempo, Loki, Prometheus) → ClickHouse → S3 스트리밍
- Parquet 포맷 압축으로 저장 비용 최적화
- 시간/날짜 기반 파티셔닝으로 쿼리 성능 최적화

_ETL 파이프라인_

- AWS Glue를 통한 ETL 작업 자동화
- 비즈니스 데이터(매출, 리텐션, 전환율)와 OTel 데이터 결합
- 데이터 스키마 설계 및 기획팀 대상 쿼리 가이드 제공

_시각화 및 접근성_

- Grafana 대시보드로 리텐션, 구매 전환율, 매출 등 핵심 이커머스 지표 시각화
- Athena를 통해 기획팀/마케팅팀이 직접 SQL 쿼리 실행 가능
- Acquisition(고객 획득), Conversion(전환), Retention(유지) 전체 비즈니스 퍼널 분석 환경 조성

**Achievement**

- **로그 조회 기간 142배 확장**: 7일 → **10년**
- 대용량 로그 쿼리 성능 최적화 (Parquet + Partitioning)
- 월 20TB 이상 OTel 데이터와 비즈니스 데이터 연계 플랫폼 구축
- 기획/마케팅팀의 데이터 기반 의사결정 지원
- Observability 데이터를 비즈니스 가치로 연결

**사용 기술**

- AWS Glue (Spark), Athena (Hive)
- S3, Parquet
- ClickHouse
- Grafana
- OpenTelemetry (Tempo, Loki, Prometheus)

**배운 점**

- 기술적 성과(Observability)를 비즈니스 성과(Data-driven decision)로 연결하는 것의 중요성
- 데이터의 고객은 기획/마케팅팀: 그들의 요구사항을 먼저 인터뷰하고 스키마 설계

---

#### 1.7. 레거시 Redis 클러스터 무중단 마이그레이션

**Challenge**

- 기술 지원 종료(EOL) Redis v5 클러스터
- 안정성 저하 및 장애 리스크 증가
- 서비스 중단 없이 버전 업그레이드 필요
- 데이터 정합성 보장 필수

**Solution**

_Dual-Write 전략_

- 신규 **Redis v7 (LTS)** 클러스터 병렬 구축
- 애플리케이션 레이어에서 Dual-Write 구현 (기존 v5 + 신규 v7 동시 쓰기)
- 실시간 데이터 정합성 검증 스크립트 작성

_Phased Rollout (점진적 배포)_

- Canary 배포: 1% → 10% → 50% → 100% 트래픽 전환
- 각 단계별 모니터링 및 Rollback 계획 수립
- Read 트래픽부터 전환 후 Write 트래픽 전환

**Achievement**

- **서비스 중단 없이(Zero Downtime)** Redis v7 LTS로 마이그레이션 완료
- 시스템 안정성 및 확장성 확보
- 데이터 정합성 100% 유지
- 향후 3년 이상 LTS 지원 보장

**사용 기술**

- Redis v5 (legacy), Redis v7 (LTS)
- Dual-Write pattern
- Canary deployment
- Python (데이터 정합성 검증 스크립트)

---

#### 1.8. 개발자 경험(DX) 향상을 위한 샌드박스 환경 구축

**Challenge**

- Windows 등 다양한 로컬 환경과 실제 배포 환경(Linux) 간 불일치
- 로컬에서 테스트 한계 (컨테이너, 네트워크, DB 등)
- 신규 입사자 및 비개발 직군(기획/QA)의 테스트 접근성 부재
- 배포 전 통합 테스트 환경 부족

**Solution**

_격리된 샌드박스 환경_

- 리눅스 기반 **격리된 개인형 테스트 샌드박스(User Sandbox)** 자동 프로비저닝 시스템 구축
- Kubernetes Namespace 기반 격리
- 사용자 요청 시 자동으로 전용 리소스 할당 (CPU, Memory, Network)
- Terraform을 활용한 IaC 기반 프로비저닝

_접근성 향상_

- Web UI를 통한 원클릭 샌드박스 생성
- 기획/QA 직군도 쉽게 사용 가능한 인터페이스 제공
- 자동 삭제 정책으로 리소스 낭비 방지

**Achievement**

- 로컬 환경 의존성 제거로 **배포 전 테스트 편의성 및 안정성 대폭 향상**
- 기획/QA 직군의 테스트 참여 활성화로 조기 버그 발견율 증가
- 신규 입사자 온보딩 시간 단축
- 개발자가 인프라 걱정 없이 비즈니스 로직에 집중 가능

**사용 기술**

- Kubernetes (Namespace 격리)
- Terraform (IaC)
- React (Web UI)
- Python (백엔드 API)

**배운 점**

- **Developer Experience (DX)** 의 핵심: 개발자가 인프라가 아닌 비즈니스 로직에 집중하도록
- 비개발 직군의 테스트 참여가 품질 향상에 기여

---

## 2. 애버커스 (Abacus)

### 기본 정보

- **기간**: 2023년 05월 ~ 2024년 06월 (1년 2개월)
- **직급**: 선임연구원 (Frontend Project Leader)
- **회사 소개**: LG/SK 협력 SI 회사
- **담당 업무**: Kubernetes, AWS 환경 기반 MSA 구축 및 프론트엔드 프로젝트 리딩

### 주요 프로젝트

#### 2.1. LG 바이올렛(Violet) 환경 전환 및 MSA 구축

**Challenge**

- LG의 신규 Kubernetes 기반 '바이올렛' 플랫폼 표준 환경 도입
- 전사 MSA 표준 환경 구축 필요
- 온프레미스 Kubernetes 클러스터 처음부터 구축
- LG의 높은 보안 요구사항 충족

**Solution**

_Kubernetes 클러스터 구축_

- **Kubernetes 클러스터 구축** (Master 1대, Worker 2대)
- CNI(Container Network Interface) 네트워킹 레이어 설정
- 보안 컨텍스트 설정 (Pod Security Policy, RBAC)
- Persistent Volume 구성 (NFS, Local Storage)

_인증/인가 시스템_

- **Keycloak** 기반 SSO(Single Sign-On) 시스템 구현
- LDAP 연동으로 기존 LG 계정 체계 통합
- Role-Based Access Control (RBAC) 설정

_마이크로서비스 개발_

- **Spring Boot** 와 **Python(FastAPI)** 기반 API 서버 개발
- **APISIX Gateway** 를 통한 마이크로서비스 통신 관리
- Service Mesh 패턴 적용

**Achievement**

- LG 바이올렛 환경에서 **유일한 기술력 보유 파트너사**로 인정
- 프로젝트 성공으로 인한 **매출 300% 증가**
- Kubernetes, SSO, MSA 전체 아키텍처 설계 및 구축 경험
- 클라이언트(LG)와 내부팀 간 기술 커뮤니케이션 주도

**사용 기술**

- Kubernetes (on-premise, Master-Worker cluster)
- Keycloak (SSO, LDAP)
- Spring Boot, Python FastAPI
- APISIX Gateway
- Docker

**배운 점**

- 온프레미스 Kubernetes 구축의 복잡성 (특히 네트워킹, 스토리지)
- 기업 환경의 높은 보안 요구사항 충족 방법
- Frontend Project Leader로서 클라이언트-내부팀-개발팀 간 커뮤니케이션의 중요성

---

#### 2.2. LG U+ 실내배송로봇/안내로봇 플랫폼

**Challenge**

- 건물과 층별로 상이한 지도 스케일에 따른 로봇 위치 매핑 오류
- 실세계 좌표(미터)와 지도 픽셀 좌표 간 변환 문제
- 서버 측 인력 부족으로 백엔드 개발 병행 필요
- 실시간 로봇 상태 관리 및 모니터링 체계 구축

**Solution**

_M2PX 알고리즘 독자 개발_

- **M2PX (Meter to Pixel) 변환 알고리즘** 독자 개발
- 실세계 좌표(미터)를 픽셀 좌표로 정확하게 변환
- 층별/건물별 다른 지도 스케일 자동 처리
- 회전, 확대/축소를 고려한 Affine 변환 구현

_실시간 메시징 시스템_

- **RabbitMQ** 메시지 큐 시스템 구축
- 실시간 로봇 상태(위치, 배터리, 작업 상태) 관리
- Pub/Sub 패턴으로 다수 로봇 동시 모니터링

_디바이스 통신_

- **AWS IoT Core** MQTTS-WebSocket 연동
- 안정적인 디바이스 통신 구현
- 재연결 및 오류 처리 메커니즘

**Achievement**

- 평균 응답 시간 **200ms 이하** 달성
- **동시 100대 이상** 로봇 관제 가능
- 정확한 실내 위치 추적으로 배송 성공률 향상
- M2PX 알고리즘: 독자적인 기술 자산 확보

**사용 기술**

- Python (M2PX 알고리즘, FastAPI)
- RabbitMQ
- AWS IoT Core, MQTTS, WebSocket
- 좌표 변환 알고리즘 (Affine transformation)

**배운 점**

- 도메인 지식 (로봇공학, 지도 좌표 체계)의 중요성
- 실시간 시스템에서의 메시지 큐 활용
- 서버 개발자 부족 시 풀스택으로 프로젝트 리딩

---

#### 2.3. SK 드론 관제 플랫폼 고도화

**Challenge**

- **500MB 이상** 대용량 3D 모델 파일 렌더링 성능 저하
- 브라우저 메모리 부족 및 렌더링 지연
- PWA(Progressive Web App) 캐시와 CloudFront 충돌 이슈
- 드론 촬영 이미지의 GPS 정보 추출 필요

**Solution**

_3D 렌더링 최적화_

- **Three.js** 기반 **LOD (Level of Detail) 최적화** 구현
- 카메라 거리에 따라 모델 디테일 자동 조절
- 메모리 사용량 및 렌더링 부하 최소화
- Frustum Culling 적용으로 보이지 않는 객체 렌더링 제외

_GPS 정보 추출_

- 드론 촬영 이미지의 **EXIF 메타데이터**에서 GPS 위치 정보 추출 시스템 개발
- Python Pillow 라이브러리 활용
- 위치 정보를 지도에 자동 매핑

_API 연동 및 보안_

- **SK T Map API** 연동으로 실시간 드론 위치 추적
- **AWS WAF**를 통한 보안 강화 (DDoS 방어, Rate limiting)

**Achievement**

- 3D 렌더링 성능 **70% 개선**
- **동시 50대** 드론 실시간 관제 지원
- 대용량 3D 모델의 부드러운 인터랙션 제공
- PWA 캐시 충돌 이슈 해결

**사용 기술**

- Three.js (LOD optimization, Frustum Culling)
- React, PWA
- AWS CloudFront, WAF
- EXIF metadata (Python Pillow)
- SK T Map API

**배운 점**

- 3D 렌더링 최적화 기법 (LOD, Frustum Culling)
- PWA와 CDN 캐시 전략
- 대용량 에셋 처리 최적화

---

#### 2.4. LG IXI Generative AI 플랫폼 (추가)

**Challenge**

- 실시간 AI 응답 스트리밍 구현
- Chat, Code Editor POC 품질 개선
- Kubernetes + Istio service mesh 환경
- CodeMirror 브라우저 레퍼런스 이슈

**Solution**

_실시간 스트리밍_

- **Server-Sent Events (SSE)** 를 통한 실시간 AI 응답 스트리밍 구현
- React에서 EventSource API 활용
- 연결 끊김 시 자동 재연결 메커니즘

_Code Editor 개선_

- CodeMirror 브라우저 레퍼런스 이슈 해결
- Syntax highlighting 최적화
- AI 코드 제안 기능 통합

**Achievement**

- 실시간 AI 응답으로 사용자 경험 향상
- Chat, Code Editor POC 품질 개선
- Istio service mesh 환경에서 안정적인 스트리밍 구현

**사용 기술**

- Server-Sent Events (SSE)
- React, CodeMirror
- Kubernetes, Istio

---

#### 2.5. In-house Next.js Framework 개발 (추가)

**Challenge**

- 클라이언트 프로젝트마다 반복되는 설정 및 컴포넌트 개발
- 개발 속도 향상 필요
- 일관된 UI/UX 제공

**Solution**

_프레임워크 개발_

- Next.js 기반 in-house 프레임워크 구축
- **React Aria**, **React Spectrum** 을 활용한 접근성 있는 UI 컴포넌트
- **Storybook**으로 컴포넌트 문서화
- SSR, SSG 등 다양한 렌더링 전략 지원
- CORS 등 네트워크 설정 가이드 제공

**Achievement**

- 클라이언트 프로젝트 개발 속도 향상
- 재사용 가능한 고품질 컴포넌트 라이브러리 구축
- Storybook으로 개발자 간 협업 효율 증대

**사용 기술**

- Next.js, React
- React Aria, React Spectrum
- Storybook

---

## 3. 인아웃박스 (Inoutbox)

### 기본 정보

- **기간**: 2022년 06월 ~ 2023년 03월 (10개월)
- **직급**: 1인 풀스택 개발 (개인 창업)
- **회사 소개**: 의류 도매 B2B/B2C 플랫폼 스타트업
- **담당 업무**: 서비스 기획, 설계, 개발, 인프라 운영 총괄 (End-to-End)

### 주요 프로젝트

#### 3.1. 동대문 B2B/B2C 통합 이커머스 플랫폼 구축

**Challenge**

- 도매업자와 소매업자를 위한 통합 플랫폼 부재
- 도매-소매업자 간 분리된 주문/재고 시스템 통합
- POS 영수증 출력 시 다양한 프린터 기기별 호환성 문제
- 1인 개발자로서 전체 스택 개발 및 운영

**Solution**

_크로스 플랫폼 앱 개발_

- **Flutter** 기반 크로스 플랫폼 사입 앱 개발 (Android/iOS)
- 단일 코드베이스로 개발 속도 향상
- 실시간 재고 확인 및 주문 관리 기능

_POS 프린터 호환성_

- **디바이스별 맞춤 DOM 생성 및 CSS 최적화** 로직 구현
- 다양한 POS 프린터 모델 (Epson, Star, Bixolon 등) 호환성 확보
- 영수증 레이아웃 자동 조정
- 각 프린터의 ESC/POS 명령어 프로파일링

_관측성 및 알림_

- **GCP Logging** 중앙화
- **Slack 연동**을 통한 실시간 장애 알림 시스템 구축
- 서비스 장애 즉시 감지 및 대응
- 에러 로그 자동 분류 및 알림

_백엔드 개발_

- **Vue.js** (프론트엔드) + **Python Django** (백엔드)
- RESTful API 설계
- 도매/소매 주문 통합 로직 구현

**Achievement**

- **월 거래액 10억원** 달성
- **동시 접속자 1,000명** 안정적 처리
- 평균 응답 시간 **300ms** 유지
- 1인 개발자로서 End-to-End Ownership 경험
- 새벽 3시 장애 대응 등 실전 운영 경험

**사용 기술**

- Flutter (Android/iOS)
- Vue.js, Python Django
- GCP Logging, Firebase
- Slack API
- ESC/POS (프린터 프로토콜)

**배운 점**

- **진정한 Ownership**: 기획부터 개발, 배포, 운영, 장애 대응까지 모두 경험
- 크로스 플랫폼 개발의 생산성
- POS 하드웨어 통합의 복잡성
- 1인 개발자의 한계와 우선순위 관리의 중요성

---

#### 3.2. 캠핑 SNS 모바일 앱 (추가)

**Challenge**

- 이미지 편집 기능 필요 (Pinch-to-zoom, 크롭, 회전)
- Flutter 생태계에 적합한 라이브러리 부재

**Solution**

_커스텀 이미지 편집 라이브러리_

- Flutter용 커스텀 이미지 편집 라이브러리 개발
- Pinch-to-zoom, Cropping, Rotation 기능 구현
- Canvas API 활용한 저수준 이미지 처리

**Achievement**

- 사용자 맞춤형 이미지 편집 기능 제공
- Flutter 생태계에 기여 가능한 라이브러리 개발 경험

**사용 기술**

- Flutter, Dart
- Canvas API

---

## 4. 인텔리시스 (Intellisys)

### 기본 정보

- **기간**: 2020년 02월 ~ 2022년 06월 (2년 5개월)
- **직급**: 서비스 연구원 (Full-Stack Engineer)
- **회사 소개**: AI 추천 솔루션 회사
- **담당 업무**: AI 추천 솔루션 API 서버, 웹 개발 및 ML 학습 파이프라인 자동화

### 주요 프로젝트

#### 4.1. AI 모델 학습 파이프라인 자동화

**Challenge**

- **40여 개** 쇼핑몰 데이터 수집의 수동 작업
- ETL 프로세스의 비효율성
- 데이터 품질 불일치
- ML 모델 학습 시간 지연

**Solution**

_Kubernetes 네이티브 파이프라인_

- **Argo Workflows** 기반 ML 파이프라인 구축
- Kubernetes 네이티브 워크플로우 엔진 활용
- DAG(Directed Acyclic Graph) 기반 작업 의존성 관리
- 병렬 처리로 파이프라인 속도 향상

_비동기 처리 시스템_

- **RabbitMQ + Dramatiq (Python)** 비동기 처리 시스템 구현
- 메시지 큐를 통한 안정적인 작업 분산
- 실패한 작업 자동 재시도 메커니즘
- Dead Letter Queue로 실패 작업 격리

_데이터 수집 자동화_

- 40여 개 쇼핑몰 크롤링 자동화 (BeautifulSoup, Selenium)
- 데이터 정제 및 표준화 로직 구현
- 증분 업데이트 전략으로 불필요한 크롤링 최소화

**Achievement**

- 40여 개 쇼핑몰 데이터 수집 **완전 자동화**
- **ML 모델 학습 시간 60% 단축**
- 데이터 품질 향상으로 추천 정확도 개선
- Kubernetes 네이티브 파이프라인 운영 경험

**사용 기술**

- Argo Workflows, Kubernetes
- RabbitMQ, Dramatiq, Python
- BeautifulSoup, Selenium (web scraping)
- FastAPI, Django

**배운 점**

- Kubernetes 네이티브 워크플로우의 강점
- 비동기 처리와 메시지 큐의 중요성
- 데이터 품질이 ML 모델 성능에 미치는 영향

---

#### 4.2. 카페24 앱스토어용 실시간 상품 추천 시스템

**Challenge**

- 기존 추천 시스템의 낮은 클릭률(CTR)
- 사용자 만족도 저하
- 실시간 추천 성능 요구사항 (응답 시간 100ms 이하)
- 고차원 벡터 공간에서의 빠른 유사도 검색

**Solution**

_추천 알고리즘_

- **n2 알고리즘 (Approximate Nearest Neighbors)** 기반 상품 유사도 계산 시스템 구현
- 근사 최근접 이웃 탐색으로 고차원 벡터 공간에서 빠른 검색
- **TF-IDF** 등 통계 기법을 통한 상품 텍스트 분석
- 자연어 처리로 상품 설명 키워드 추출 및 벡터화

_실시간 UI_

- **Vue.js** 기반 실시간 추천 UI 개발
- 사용자 인터랙션에 따른 즉각적인 추천 업데이트
- 무한 스크롤 및 Lazy loading 구현

_A/B 테스팅_

- A/B 테스팅을 통한 알고리즘 최적화
- 다양한 추천 전략 비교 및 최적 파라미터 탐색

**Achievement**

- 추천 클릭률(CTR) **15% 향상**
- **일일 10만 건 이상** 안정적 데이터 처리
- 추천 응답 시간 **100ms 이하** 유지
- A/B 테스팅으로 데이터 기반 최적화 경험

**사용 기술**

- Python (n2 algorithm, TF-IDF, NLP)
- Vue.js
- Redis (캐싱)
- PostgreSQL

**배운 점**

- 추천 시스템의 성능과 정확도 트레이드오프
- ANN (Approximate Nearest Neighbors) 알고리즘의 실전 적용
- A/B 테스팅의 중요성

---

## 기술 철학 및 업무 방식

### End-to-End 시스템 이해의 중요성

길지 않은 경력을 쌓아오며 가장 중요하다고 생각한 점은 **시스템의 End-to-End를 모두 파악해야 한다**는 것입니다.

특히 MSA 환경에서는 트래픽이 정말 다양한 서비스를 거치게 됩니다. 예를 들어:

- 클라이언트: Mobile App 또는 Next.js
- 클라우드 또는 온프레미스 서버
- 브라우저에서 바로 트레이싱 시작
- Airflow 배치 실행, Kafka 토픽 발행, DB 조회
- 인증 정보: JWT, 세션
- 기밀 정보: EKS Secret, HashiCorp Vault, AWS Secrets Manager

**이 중 몰라도 될 것이 있나요?** 모두 제가 속한 회사의 소프트웨어이고, 저는 소속된 전문가입니다.

### 문제 해결 우선순위

1. **가장 먼저 원인을 파악하고 해결합니다**
2. **근본적이고 코어의 문제 해결에 우선순위**를 두고 관계자들과 조율하고 설득합니다
3. 단순 패치가 아닌 **장기적이고 확장 가능한 해결책** 제시

### 리더십 철학

리더로서 제가 모든 것을 담당하지는 않겠지만, **모두의 직무에 관심을 갖고 도움**이 될 수 있습니다.

**저의 리더십 방식:**

- 혼자서든 지원자와 함께든 빠르게 **POC를 완성**합니다
- 팀원들을 초대합니다 (**선발대 역할**)
- 팀원의 일하는 모습을 보고 **공식 문서, 충분한 조사, 레퍼런스**와 함께 하는지 확인합니다

### AI 시대의 위험 요소

AI 시대에 가장 위험한 요소는 **공식 문서와 충분한 조사, 레퍼런스 없이 일하는 것**이라고 생각합니다.

저는 항상:

- 공식 문서를 우선적으로 참고
- 충분한 조사와 레퍼런스 확보
- 근본적인 이해를 바탕으로 문제 해결

### 데이터 기반 의사결정

- 감이 아닌 **측정 가능한 지표**를 통해 문제 정의
- 개선 효과를 **정량적으로 증명**
- 예: MTTI 18시간 → 10분, 비용 $5K → $2.5K, 배포 시간 2시간 → 12분

### 개발자 경험(DevEx) 중심

- 개발팀의 **Pain Point**를 먼저 파악
- 자동화 및 관측성 향상으로 개발자가 **비즈니스 로직에 집중**하도록
- 기술 도입은 기술 자체가 아닌, **팀의 문제 해결**이 목적

### 지속적 학습

- OpenTelemetry 오픈소스 기여
- AWS, Kubernetes 최신 자격증 취득
- 공식 문서 기반 학습
- 최신 기술 트렌드 파악 및 실전 적용

---

**작성일**: 2025년 11월 1일

**작성자: 최성필**
