import type { InterviewQuestion } from "@/types/portfolio";

/**
 * 오픈소스 기여 및 수정 관련 질문 (ID 114)
 * - OpenTelemetry 기여 사례
 * - 오픈소스 수정 프로세스
 */
export const tossOpensourceQuestions: InterviewQuestion[] = [
  {
    id: 114,
    category1: "Infrastructure",
    category2: "OpenSource",
    question:
      "토스 JD에서 강조하는 '오픈소스를 읽고, 필요하다면 직접 수정해본 경험'에 대해 설명해주세요.",
    answer:
      "프로덕션 환경에서 가장 답답한 순간이 '공식 문서에도 없는 버그'를 마주했을 때예요. " +
      "이슈 올리고 기다리면 몇 달 걸리고, 그동안 시스템은 멈춰 있죠. " +
      "그래서 직접 오픈소스 코드를 읽고 수정하는 역량이 DevOps에서는 필수라고 생각합니다.\n\n" +
      "가장 기억에 남는 사례는 OpenTelemetry의 AWS SDK Context Propagation 버그였어요.\n\n" +
      "문제 상황: AWS Lambda에서 DynamoDB를 호출할 때 trace context가 갑자기 손실되었습니다. " +
      "분산 추적이 끊겨서 전체 트랜잭션을 추적할 수 없었죠. 공식 문서에는 'works out of the box'라고 나와 있는데 실제로는 동작하지 않았어요.\n\n" +
      "디버깅 과정: 먼저 최소 재현 케이스를 만들었어요. OpenTelemetry의 awsTracer 코드를 직접 읽어보니, " +
      "AWS SDK의 context.Value 호환성 문제가 있었습니다. AWS SDK는 자체 context를 사용하는데, " +
      "OpenTelemetry의 context가 제대로 전파되지 않았던 거죠.\n\n" +
      "해결: awsTracer의 Start 함수를 패치해서 awscontext.Context를 명시적으로 체크하고, " +
      "trace context를 수동으로 전파하도록 수정했습니다. PR을 올렸고, 리뷰어 피드백을 받아 개선한 후 병합되었어요.\n\n" +
      "배운 점: 오픈소스 기여는 단순히 '버그 수정'이 아니라 '커뮤니티와 대화하는 과정'이라는 걸 깨달았어요. " +
      "코드만 던지는 게 아니라, 재현 방법과 변경 이유, 영향 범위를 명확히 설명해야 신뢰를 얻을 수 있더라고요.\n\n" +
      "토스에서도 비슷한 상황이 있을 거라고 생각해요. Istio나 Kubernetes를 금융 환경에 맞게 커스터마이징해야 하는 경우가 많을 테니까요. " +
      "단순히 사용하는 것을 넘어, 개선하고 기여하는 엔지니어가 되고 싶습니다.",
  },
  {
    id: 120,
    category1: "Infrastructure",
    category2: "OpenSource",
    question:
      "오픈소스를 다루는 본인만의 철학이나 방식이 있나요? 문제 해결 시 어떻게 접근하나요?",
    answer:
      "저는 시스템을 다룰 때 항상 '여건이 되는 만큼 오픈소스를 분석하려고' 노력합니다.\n\n" +
      "문제를 따라가다 보면, 표면적인 에러 메시지만 보고 넘어가기보다는 " +
      "'왜 이런 에러가 발생했을까?'를 계속 파고들게 되더라고요. " +
      "그러다 보면 자연스럽게 그 근본이 되는 코드까지 눈으로 보고 싶어지는 것 같아요.\n\n" +
      "구체적으로 제 프로세스를 설명하면 이렇습니다.\n\n" +
      "첫째, 문제를 마주하면 먼저 스택 트레이스를 정확히 읽습니다. " +
      "어느 라인에서, 어떤 함수 호출에서 문제가 생겼는지 파악하죠. " +
      "그리고 해당 오픈소스의 GitHub 저장소로 들어가서 그 코드 부분을 직접 읽어봅니다.\n\n" +
      "둘째, 공식 문서만으로 부족하면 이슈 트래커와 PR 히스토리를 뒤집니다. " +
      "'비슷한 문제를 겪은 사람이 있을까?' 하고 검색해보면 대부분 누군가 이미 이슈를 올렸더라고요. " +
      "그 이슈에서 메인테이너들이 어떻게 대응했는지, 어떤 workaround가 제안되었는지를 보면서 " +
      "문제의 맥락을 이해하려고 합니다.\n\n" +
      "셋째, 로컬에서 최소 재현 케이스를 만듭니다. " +
      "프로덕션 환경에서 문제가 생기면 변수가 너무 많아서 원인 파악이 어려운데, " +
      "격리된 환경에서 단순화된 케이스로 재현하면 근본 원인을 찾기 쉬워요.\n\n" +
      "특히 OpenTelemetry는 너무 마음에 들어서 오픈소스 기여가 자연스럽게 이루어지는 것 같아요. " +
      "코드베이스도 깔끔하고, 테스트 커버리지도 높고, 메인테이너들도 친절해서 PR을 올리면 빠르게 피드백을 받을 수 있어요. " +
      "AWS SDK Context Propagation 버그도 이런 과정을 거쳐서 발견하고 수정했죠.\n\n" +
      "팀 협업에서도 비슷한 방식을 적용합니다. " +
      "Jira 이슈를 받으면, 특히 크리티컬 이슈는 RFC(Request for Comments) 이슈를 별도로 구성합니다. " +
      "여러 해결 방안을 기준별로 정리하고, 팀원들과 논의해서 합의점을 찾는 걸 좋아해요.\n\n" +
      "예를 들어, Kafka Context Propagation 문제를 해결할 때도 RFC를 만들었어요.\n\n" +
      "Option A: Kafka Headers에 직접 주입 (선택)\n- 장점: 표준 W3C Trace Context 준수, 오버헤드 최소\n- 단점: Kafka Headers 미지원 레거시 시스템과 호환 불가\n\n" +
      "Option B: Message Body에 Metadata 포함\n- 장점: 레거시 호환성\n- 단점: 비즈니스 로직과 인프라 관심사 혼재\n\n" +
      "Option C: Correlation ID로 후처리 연결\n- 장점: 기존 시스템 수정 최소화\n- 단점: 실시간성 상실, 복잡한 후처리 로직\n\n" +
      "이런 식으로 3가지 옵션과 Trade-off를 정리해서 팀과 논의하면, " +
      "각자의 관점(성능/복잡도/유지보수)에서 의견을 나눌 수 있고, 데이터 기반의 합의에 도달할 수 있더라고요.\n\n" +
      "토스에서도 이런 방식이 유용할 것 같아요. " +
      "Istio 업그레이드나 새로운 기술 도입 시, RFC로 여러 방안을 팀과 공유하고, " +
      "필요하면 오픈소스 코드를 직접 분석해서 근본 원인을 찾는 엔지니어로 기여하고 싶습니다.",
  },
];
